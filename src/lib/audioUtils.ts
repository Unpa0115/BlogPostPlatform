// @ts-ignore
import ffmpeg from 'fluent-ffmpeg'
import fs from 'fs'
import OpenAI from 'openai'

/**
 * éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°æƒ…å ±ã‚’å–å¾—
 */
export async function getAudioInfo(audioPath: string): Promise<{
  duration: number;
  format: string;
  bitrate: number;
}> {
  return new Promise((resolve, reject) => {
    ffmpeg.ffprobe(audioPath, (err: any, metadata: any) => {
      if (err) {
        reject(err)
        return
      }
      
      const audioStream = metadata.streams.find((stream: any) => stream.codec_type === 'audio')
      if (!audioStream) {
        reject(new Error('No audio stream found'))
        return
      }

      resolve({
        duration: parseFloat(metadata.format.duration) || 0,
        format: metadata.format.format_name || 'unknown',
        bitrate: parseInt(audioStream.bit_rate) || 0
      })
    })
  })
}

export async function trimAudio(inputPath: string, outputPath: string, start: number, duration: number): Promise<void> {
  return new Promise((resolve, reject) => {
    ffmpeg(inputPath)
      .setStartTime(start)
      .setDuration(duration)
      .output(outputPath)
      .on('end', () => resolve())
      .on('error', (err: Error) => reject(err))
      .run()
  })
}

export async function transcribeAudioWhisper(audioPath: string, openaiApiKey: string): Promise<string> {
  const openai = new OpenAI({ apiKey: openaiApiKey })
  const audio = fs.createReadStream(audioPath)
  const resp = await openai.audio.transcriptions.create({
    file: audio,
    model: 'whisper-1',
    response_format: 'json',
    language: 'ja',
  })
  return resp.text
}

/**
 * æŒ‡å®šã—ãŸã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºãŒç¾ã‚Œã‚‹æœ€åˆã®ä½ç½®ï¼ˆç§’ï¼‰ã‚’Whisper APIã§æ¤œå‡º
 */
export async function detectKeywordPosition(audioPath: string, keyword: string, openaiApiKey: string): Promise<number | null> {
  try {
    console.log(`ğŸ” Starting keyword detection for: "${keyword}"`)
    console.log(`ğŸ“ Audio file path: ${audioPath}`)
    
    const openai = new OpenAI({ apiKey: openaiApiKey })
    const audio = fs.createReadStream(audioPath)
    
    // ã¾ãšã¯åŸºæœ¬çš„ãªæ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œ
    console.log('ğŸ“ Requesting transcription from Whisper API...')
    const resp = await openai.audio.transcriptions.create({
      file: audio,
      model: 'whisper-1',
      response_format: 'verbose_json',
      language: 'ja'
    })
    
    console.log('âœ… Transcription completed')
    console.log(`ğŸ“„ Full transcript: "${resp.text}"`)
    
    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæƒ…å ±ã‚’ãƒã‚§ãƒƒã‚¯
    const segments = (resp as any).segments || []
    console.log(`ğŸ“Š Found ${segments.length} segments`)
    
    if (segments.length === 0) {
      console.log('âŒ No segments found in transcription')
      return null
    }
    
    // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ­£è¦åŒ–ï¼ˆç©ºç™½é™¤å»ã€å°æ–‡å­—å¤‰æ›ï¼‰
    const normalizedKeyword = keyword.trim().toLowerCase()
    console.log(`ğŸ¯ Searching for keyword: "${normalizedKeyword}"`)
    
    // å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œç´¢
    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i]
      const segmentText = (segment.text || '').toLowerCase()
      
      console.log(`ğŸ“ Segment ${i + 1}: "${segment.text}" (${segment.start}s - ${segment.end}s)`)
      
      // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
      if (segmentText.includes(normalizedKeyword)) {
        console.log(`âœ… Keyword found in segment ${i + 1} at ${segment.start}s`)
        return segment.start
      }
    }
    
    // å®Œå…¨ä¸€è‡´ã—ãªã„å ´åˆã€éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
    console.log('ğŸ” Exact match not found, checking partial matches...')
    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i]
      const segmentText = (segment.text || '').toLowerCase()
      
      // ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®å˜èªã‚’åˆ†å‰²ã—ã¦éƒ¨åˆ†ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯
      const keywordWords = normalizedKeyword.split(/\s+/)
      let matchScore = 0
      
      for (const word of keywordWords) {
        if (segmentText.includes(word)) {
          matchScore++
        }
      }
      
      // 50%ä»¥ä¸Šãƒãƒƒãƒã—ãŸå ´åˆã‚’æœ‰åŠ¹ã¨ã™ã‚‹
      if (matchScore / keywordWords.length >= 0.5) {
        console.log(`âœ… Partial keyword match (${matchScore}/${keywordWords.length}) found in segment ${i + 1} at ${segment.start}s`)
        return segment.start
      }
    }
    
    console.log('âŒ Keyword not found in any segment')
    return null
    
  } catch (error) {
    console.error('âŒ Error in keyword detection:', error)
    
    // OpenAI APIã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’å‡ºåŠ›
    if (error instanceof Error) {
      console.error('Error message:', error.message)
      console.error('Error stack:', error.stack)
    }
    
    // APIã‚¨ãƒ©ãƒ¼ã®å ´åˆã®è©³ç´°æƒ…å ±
    if ((error as any).response) {
      console.error('API Response Status:', (error as any).response.status)
      console.error('API Response Data:', (error as any).response.data)
    }
    
    throw new Error(`Keyword detection failed: ${error instanceof Error ? error.message : 'Unknown error'}`)
  }
}

/**
 * ffmpegã§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å…ˆé ­ãƒ»æœ«å°¾ã®ç„¡éŸ³åŒºé–“ï¼ˆç§’ï¼‰ã‚’æ¤œå‡º
 * @returns { start: number, duration: number }
 */
export async function detectSilence(inputPath: string): Promise<{ start: number, duration: number }> {
  return new Promise((resolve, reject) => {
    let silenceStart = 0
    let silenceEnd = 0
    let duration = 0
    const tempOutputPath = inputPath.replace(/\.[^/.]+$/, '_temp_silence.mp3')
    
    ffmpeg(inputPath)
      .audioFilters('silencedetect=n=-50dB:d=0.5')
      .output(tempOutputPath) // å‡ºåŠ›ãƒ‘ã‚¹ã‚’æŒ‡å®š
      .on('stderr', (line: string) => {
        // ffmpegã®stderrã‹ã‚‰silence_start/silence_endã‚’æŠ½å‡º
        const silenceStartMatch = line.match(/silence_start: (\d+\.?\d*)/)
        const silenceEndMatch = line.match(/silence_end: (\d+\.?\d*)/)
        const durationMatch = line.match(/Duration: (\d+):(\d+):(\d+\.?\d*)/)
        if (silenceStartMatch) silenceStart = parseFloat(silenceStartMatch[1])
        if (silenceEndMatch) silenceEnd = parseFloat(silenceEndMatch[1])
        if (durationMatch) {
          duration = parseInt(durationMatch[1]) * 3600 + parseInt(durationMatch[2]) * 60 + parseFloat(durationMatch[3])
        }
      })
      .on('end', () => {
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        fs.unlink(tempOutputPath, () => {})
        // ç„¡éŸ³åŒºé–“ã‚’é™¤ã„ãŸstart/durationã‚’è¿”ã™
        resolve({ start: silenceEnd, duration: duration - silenceEnd })
      })
      .on('error', (err: Error) => {
        // ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        fs.unlink(tempOutputPath, () => {})
        reject(err)
      })
      .run()
  })
}

// TODO: ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæ¤œå‡ºã‚„ç„¡éŸ³éƒ¨åˆ†æ¤œå‡ºãªã©ã‚‚è¿½åŠ å¯èƒ½ 